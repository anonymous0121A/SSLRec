optimizer:
  name: adam
  lr: 1.0e-3 # not 1e-3
  weight_decay: 0

train:
  epoch: 200
  batch_size: 512
  save_model: true
  test_step: 1 # evaluate per {test_step} epochs
  #pretrain_path: ./checkpoint/xxxx.pth
  reproducible: true
  seed: 2023

test:
  metrics: [recall, ndcg] # choose in {ndcg, recall, precision, mrr}
  k: [5, 10] # top-k
  batch_size: 512 # How many users per batch during validation

data:
  type: sequential # choose in {general_cf, multi_behavior, sequential, social}
  name: ml-20m
  seq_aug: true

model:
  name: cl4srec # case-insensitive
  dropout_rate: 0.1
  n_layers: 2
  embedding_size: 64
  n_heads: 2
  max_seq_len: 50
  lmd: 0.1
  tau: 1

tune:
  enable: true # Whether to enable grid search to search for optimal hyperparameters
  hyperparameters: [dropout_rate, lmb, tau] # The name of the hyperparameter
  dropout_rate: [0.1, 0.3, 0.5] # Use a list to store the search range
  lmb: [0.05, 0.1, 0.2]
  tau: [0.5, 0.7, 0.9]
